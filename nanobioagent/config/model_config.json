{
  "_metadata": {
    "version": "2.0",
    "description": "Converted from CSV format",
    "created": "2025-08-19"
  },
  "nvidia_nim_prefixes": [
    "deepseek-ai/",
    "google/",
    "ibm/",
    "llama-3.1-nemotron",
    "llama-3.3-nemotron",
    "nvidia/",
    "marin/",
    "meta/",
    "microsoft/",
    "mistralai/",
    "nv-mistralai/",
    "qwen/",
    "tiiuae/",
    "zyphra/",
    "openai/"
  ],
  "_defaults": {
    "cut_length": 18000,
    "max_tokens": 512,
    "model_type": "chat",
    "context_window": 32000,
    "temperature": 0,
    "doc": "https://huggingface.co/",
    "pricing": {
      "input": 0.001,
      "output": 0.004,
      "per_tokens": 1000
    }
  },
  "models": {
    "gpt-3.5-turbo": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "openai",
      "context_window": 16385,
      "doc": "https://platform.openai.com/docs/models/gpt-3.5-turbo",
      "pricing": {
        "input": 0.5,
        "output": 1.5,
        "per_tokens": 1000000
      }
    },
    "gpt-4.1-mini": {
      "cut_length": 72000,
      "max_tokens": 512,
      "model_type": "openai",
      "context_window": 1000000,
      "doc": "https://platform.openai.com/docs/models/gpt-4.1-mini",
      "pricing": {
        "input": 0.4,
        "output": 1.6,
        "per_tokens": 1000000
      }
    },
    "gpt-4.1-nano": {
      "cut_length": 72000,
      "max_tokens": 512,
      "model_type": "openai",
      "context_window": 1000000,
      "doc": "https://platform.openai.com/docs/models/gpt-4.1-nano",
      "pricing": {
        "input": 0.1,
        "output": 0.4,
        "per_tokens": 1000000
      }
    },
    "gpt-4.1": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "openai",
      "context_window": 500000,
      "doc": "https://platform.openai.com/docs/models/gpt-4.1",
      "pricing": {
        "input": 2,
        "output": 8,
        "per_tokens": 1000000
      }
    },
    "gpt-4o-mini": {
      "cut_length": 72000,
      "max_tokens": 512,
      "model_type": "openai",
      "context_window": 128000,
      "doc": "https://platform.openai.com/docs/models/gpt-4o-mini",
      "pricing": {
        "input": 0.15,
        "output": 0.6,
        "per_tokens": 1000000
      }
    },
    "gpt-4o": {
      "cut_length": 72000,
      "max_tokens": 512,
      "model_type": "openai",
      "context_window": 128000,
      "doc": "https://platform.openai.com/docs/models/gpt-4o",
      "pricing": {
        "input": 2.5,
        "output": 10,
        "per_tokens": 1000000
      }
    },
    "gpt-5-mini": {
      "cut_length": 96000,
      "max_tokens": 4096,
      "model_type": "openai",
      "context_window": 272000,
      "temperature": 1,
      "doc": "https://platform.openai.com/docs/models/gpt-5-mini",
      "pricing": {
        "input": 0.25,
        "output": 2,
        "per_tokens": 1000000
      }
    },
    "gpt-5-nano": {
      "cut_length": 96000,
      "max_tokens": 4096,
      "model_type": "openai",
      "context_window": 272000,
      "temperature": 1,
      "doc": "https://platform.openai.com/docs/models/gpt-5-nano",
      "pricing": {
        "input": 0.05,
        "output": 0.4,
        "per_tokens": 1000000
      }
    },
    "claude-3-5-haiku-20241022": {
      "cut_length": 54000,
      "max_tokens": 512,
      "model_type": "anthropic",
      "context_window": 200000,
      "doc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-3-5",
      "pricing": {
        "input": 0.8,
        "output": 4,
        "per_tokens": 1000000
      }
    },
    "claude-3-7-sonnet-20250219": {
      "cut_length": 54000,
      "max_tokens": 512,
      "model_type": "anthropic",
      "context_window": 200000,
      "doc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-3-7",
      "pricing": {
        "input": 3,
        "output": 15,
        "per_tokens": 1000000
      }
    },
    "claude-sonnet-4-20250514": {
      "cut_length": 54000,
      "max_tokens": 512,
      "model_type": "anthropic",
      "context_window": 200000,
      "doc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-4",
      "pricing": {
        "input": 3,
        "output": 15,
        "per_tokens": 1000000
      }
    },
    "claude-opus-4-1-20250805": {
      "cut_length": 54000,
      "max_tokens": 512,
      "model_type": "anthropic",
      "context_window": 200000,
      "doc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/opus-4-1",
      "pricing": {
        "input": 15,
        "output": 75,
        "per_tokens": 1000000
      }
    },
    "gemini-1.5-flash": {
      "cut_length": 30000,
      "max_tokens": 512,
      "model_type": "google",
      "context_window": 1048575,
      "doc": "https://ai.google.dev/gemini-api/docs/pricing#gemini-1.5-flash",
      "pricing": {
        "input": 0.075,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "gemini-1.5-flash-8b": {
      "cut_length": 30000,
      "max_tokens": 512,
      "model_type": "google",
      "context_window": 1048575,
      "doc": "https://ai.google.dev/gemini-api/docs/pricing#gemini-1.5-flash-8b",
      "num_parameters": 8000000000,
      "pricing": {
        "input": 0.0375,
        "output": 0.15,
        "per_tokens": 1000000
      }
    },
    "gemini-2.0-flash": {
      "cut_length": 30000,
      "max_tokens": 512,
      "model_type": "google",
      "context_window": 1048575,
      "doc": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash",
      "pricing": {
        "input": 0.1,
        "output": 0.4,
        "per_tokens": 1000000
      }
    },
    "gemini-2.0-flash-lite": {
      "cut_length": 30000,
      "max_tokens": 512,
      "model_type": "google",
      "context_window": 1048575,
      "doc": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite",
      "pricing": {
        "input": 0.075,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "gemini-2.5-flash": {
      "cut_length": 96000,
      "max_tokens": 512,
      "model_type": "google",
      "context_window": 1048575,
      "doc": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash",
      "pricing": {
        "input": 0.3,
        "output": 2.5,
        "per_tokens": 1000000
      }
    },
    "gemini-2.5-flash-lite": {
      "cut_length": 96000,
      "max_tokens": 512,
      "model_type": "google",
      "context_window": 1048575,
      "doc": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-lite",
      "pricing": {
        "input": 0.1,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "nvidia/llama-3.3-nemotron-super-49b-v1.5": {
      "cut_length": 16000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "thinking_control_prompt": "/no_think",
      "doc": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5",
      "num_parameters": 49900000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "nvidia/llama-3.1-nemotron-51b-instruct": {
      "cut_length": 16000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-51b-instruct",
      "num_parameters": 51500000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "nvidia/llama-3.1-nemotron-ultra-253b-v1": {
      "cut_length": 16000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "thinking_control_prompt": "detailed thinking off.",
      "doc": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1",
      "num_parameters": 253000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "meta/llama-4-scout-17b-16e-instruct": {
      "cut_length": 96000,
      "max_tokens": 1024,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/meta/llama-4-scout-17b-16e-instruct",
      "num_parameters": 109000000000,
      "pricing": {
        "input": 0.18,
        "output": 0.59,
        "per_tokens": 1000000
      }
    },
    "meta/llama-3.3-70b-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/meta/llama-3_3-70b-instruct",
      "num_parameters": 70600000000,
      "pricing": {
        "input": 0.88,
        "output": 0.88,
        "per_tokens": 1000000
      }
    },
    "meta/llama-3.2-3b-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/meta/llama-3.2-3b-instruct",
      "num_parameters": 3210000000,
      "pricing": {
        "input": 0.06,
        "output": 0.06,
        "per_tokens": 1000000
      }
    },
    "meta/llama-3.1-405b-instruct": {
      "cut_length": 96000,
      "max_tokens": 1024,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/meta/llama-3_1-405b-instruct",
      "num_parameters": 406000000000,
      "pricing": {
        "input": 3.5,
        "output": 3.5,
        "per_tokens": 1000000
      }
    },
    "meta/llama-3.1-8b-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/meta/llama-3_1-8b-instruct",
      "num_parameters": 8030000000,
      "pricing": {
        "input": 0.18,
        "output": 0.18,
        "per_tokens": 1000000
      }
    },
    "google/gemma-3-1b-it": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/google/gemma-3-1b-it",
      "num_parameters": 1000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "google/gemma-2-9b-it": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 4096,
      "temperature": 0.01,
      "doc": "https://build.nvidia.com/google/gemma-2-9b-it",
      "num_parameters": 9000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "google/gemma-2-2b-it": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 4096,
      "temperature": 0.01,
      "doc": "https://build.nvidia.com/google/gemma-2-2b-it",
      "num_parameters": 2000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "google/gemma-3-27b-it": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/google/gemma-3-27b-it",
      "num_parameters": 27000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ibm/granite-3.3-8b-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 65536,
      "doc": "https://build.nvidia.com/ibm/granite-3_3-8b-instruct",
      "num_parameters": 8170000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "qwen/qwen3-235b-a22b": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 40960,
      "thinking_control_prompt": "/no_think",
      "doc": "https://build.nvidia.com/qwen/qwen3-235b-a22b",
      "num_parameters": 235000000000,
      "pricing": {
        "input": 0.2,
        "output": 0.6,
        "per_tokens": 1000000
      }
    },
    "qwen/qwen3-coder-480b-a35b-instruct": {
      "cut_length": 96000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 262144,
      "doc": "https://build.nvidia.com/qwen/qwen3-coder-480b-a35b-instruct",
      "num_parameters": 480000000000,
      "pricing": {
        "input": 2,
        "output": 2,
        "per_tokens": 1000000
      }
    },
    "qwen/qwen2.5-coder-7b-instruct": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/qwen/qwen2_5-coder-7b-instruct",
      "num_parameters": 7620000000,
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "qwen/qwen2.5-coder-32b-instruct": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/qwen/qwen2_5-coder-32b-instruct",
      "num_parameters": 32800000000,
      "pricing": {
        "input": 0.8,
        "output": 0.8,
        "per_tokens": 1000000
      }
    },
    "qwen/qwen2.5-7b-instruct": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/qwen/qwen2_5-7b-instruct",
      "num_parameters": 7620000000,
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "nvidia/nvidia-nemotron-nano-9b-v2": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 128000,
      "thinking_control_prompt": "/no_think",
      "doc": "https://build.nvidia.com/nvidia/nvidia-nemotron-nano-9b-v2",
      "num_parameters": 8890000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "mistralai/mistral-7b-instruct-v0.3": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/mistralai/mistral-7b-instruct-v03",
      "num_parameters": 7250000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "mistralai/mixtral-8x7b-instruct-v0.1": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/mistralai/mixtral-8x7b-instruct",
      "num_parameters": 46700000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "mistralai/mistral-nemotron": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 128000,
      "doc": "https://build.nvidia.com/mistralai/mistral-nemotron",
      "num_parameters": 12000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "microsoft/phi-4-mini-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 131072,
      "doc": "https://build.nvidia.com/microsoft/phi-4-mini-instruct",
      "num_parameters": 3800000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "microsoft/phi-3-small-128k-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 16000,
      "temperature": 0.01,
      "doc": "https://build.nvidia.com/microsoft/phi-3-small-128k-instruct",
      "num_parameters": 7390000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "microsoft/phi-3.5-mini-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 128000,
      "doc": "https://build.nvidia.com/microsoft/phi-3_5-mini",
      "num_parameters": 3820000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "microsoft/phi-4-multimodal-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 128000,
      "doc": "https://build.nvidia.com/microsoft/phi-4-multimodal-instruct",
      "num_parameters": 5570000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "nv-mistralai/mistral-nemo-12b-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 127999,
      "doc": "https://build.nvidia.com/nv-mistralai/mistral-nemo-12b-instruct",
      "num_parameters": 12000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "tiiuae/falcon3-7b-instruct": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 32768,
      "doc": "https://build.nvidia.com/tiiuae/falcon3-7b-instruct",
      "num_parameters": 7220000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/meditron:7b": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 2000,
      "doc": "https://ollama.com/library/meditron:7b",
      "num_parameters": 6740000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/llama3:8b": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 8000,
      "doc": "https://ollama.com/library/llama3:8b",
      "num_parameters": 8030000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/llama2:latest": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 2048,
      "doc": "https://ollama.com/library/llama2:latest",
      "num_parameters": 6740000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/codellama:7b-instruct": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 2048,
      "doc": "https://ollama.com/library/codellama:7b-instruct",
      "num_parameters": 6740000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/gemma3:12b-it-qat": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 128000,
      "doc": "https://ollama.com/library/gemma3:12b-it-qat",
      "num_parameters": 12200000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/qwen3:8b": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 32768,
      "thinking_control_prompt": "/no_think",
      "doc": "https://ollama.com/library/qwen3:8b",
      "num_parameters": 8190000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "ollama/qwen2.5-coder-7b-instruct": {
      "cut_length": 8000,
      "max_tokens": 512,
      "model_type": "ollama",
      "context_window": 32768,
      "doc": "https://ollama.com/library/qwen2.5-coder:7b-instruct",
      "num_parameters": 7620000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "huggingface/Qwen/Qwen2.5-Coder-3B-Instruct": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "huggingface",
      "context_window": 32768,
      "doc": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct",
      "num_parameters": 3090000000,
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "huggingface/Qwen/Qwen2.5-72B-Instruct": {
      "cut_length": 36000,
      "max_tokens": 512,
      "model_type": "huggingface",
      "context_window": 128000,
      "doc": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct",
      "num_parameters": 72700000000,
      "pricing": {
        "input": 1.2,
        "output": 1.2,
        "per_tokens": 1000000
      }
    },
    "huggingface/google/gemma-3-12b-it:featherless-ai": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "huggingface",
      "context_window": 131072,
      "doc": "https://huggingface.co/google/gemma-3-12b-it",
      "num_parameters": 12200000000,
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "huggingface/microsoft/phi-4": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "huggingface",
      "context_window": 16000,
      "doc": "https://huggingface.co/microsoft/phi-4",
      "num_parameters": 14700000000,
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "per_tokens": 1000000
      }
    },
    "mistralai/mistral-small-3.1-24b-instruct-2503": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "nvidia_nim",
      "context_window": 128000,
      "doc": "https://build.nvidia.com/mistralai/mistral-small-3_1-24b-instruct-2503",
      "num_parameters": 24000000000,
      "pricing": {
        "input": 0.001,
        "output": 0.004,
        "per_tokens": 1000
      }
    },
    "huggingface/moonshotai/Kimi-K2-Instruct-0905": {
      "cut_length": 96000,
      "max_tokens": 1024,
      "model_type": "huggingface",
      "context_window": 256000,
      "doc": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905",
      "num_parameters": 1000000000000,
      "pricing": {
        "input": 1,
        "output": 3,
        "per_tokens": 1000000
      }
    },
    "huggingface/zai-org/GLM-4-9B-0414:featherless-ai": {
      "cut_length": 18000,
      "max_tokens": 512,
      "model_type": "huggingface",
      "context_window": 32000,
      "doc": "https://huggingface.co/zai-org/GLM-4-9B-0414",
      "num_parameters": 9400000000,
      "pricing": {
        "input": 0.2,
        "output": 1.1,
        "per_tokens": 1000000
      }
    },
    "HuggingFaceTB/SmolLM-360M": {
      "model_type": "local"
    },
    "HuggingFaceTB/SmolLM2-360M-Instruct": {
      "model_type": "local"
    },
    "ibm-granite/granite-4.0-350M": {
      "model_type": "local"
    }
  }
}